{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for Topic Modeling slides - Joe Biden Tweets\n",
    "- Stephen W. Thomas\n",
    "- Used for MMA 865; MMAI 891; Exec Ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-01 08:14:07.735002\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4694 entries, 0 to 4693\n",
      "Data columns (total 7 columns):\n",
      "id           4694 non-null float64\n",
      "username     4694 non-null object\n",
      "timestamp    4694 non-null object\n",
      "link         4694 non-null object\n",
      "tweet        4694 non-null object\n",
      "retweets     4694 non-null int64\n",
      "likes        4694 non-null int64\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 256.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>link</th>\n",
       "      <th>tweet</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.278830e+18</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>7/3/2020 5:00</td>\n",
       "      <td>https://twitter.com/JoeBiden/status/1278833330...</td>\n",
       "      <td>Wear a mask. pic. twitter.com/HBDMNA4ary</td>\n",
       "      <td>18191</td>\n",
       "      <td>92047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.278810e+18</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>7/3/2020 3:25</td>\n",
       "      <td>https://twitter.com/JoeBiden/status/1278809602...</td>\n",
       "      <td>Let me be clear: There’s no victory to be cele...</td>\n",
       "      <td>10644</td>\n",
       "      <td>47486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.278780e+18</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>7/3/2020 1:15</td>\n",
       "      <td>https://twitter.com/JoeBiden/status/1278776708...</td>\n",
       "      <td>This is a job Donald Trump is entirely unfit f...</td>\n",
       "      <td>15149</td>\n",
       "      <td>51443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.278750e+18</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>7/2/2020 23:18</td>\n",
       "      <td>https://twitter.com/JoeBiden/status/1278747263...</td>\n",
       "      <td>“Mr. President, it's too much.”pic.twitter.com...</td>\n",
       "      <td>44466</td>\n",
       "      <td>137553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.278730e+18</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>7/2/2020 22:23</td>\n",
       "      <td>https://twitter.com/JoeBiden/status/1278733658...</td>\n",
       "      <td>This is a shameful move. Now is the time for e...</td>\n",
       "      <td>6357</td>\n",
       "      <td>23150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  username       timestamp  \\\n",
       "0  1.278830e+18  JoeBiden   7/3/2020 5:00   \n",
       "1  1.278810e+18  JoeBiden   7/3/2020 3:25   \n",
       "2  1.278780e+18  JoeBiden   7/3/2020 1:15   \n",
       "3  1.278750e+18  JoeBiden  7/2/2020 23:18   \n",
       "4  1.278730e+18  JoeBiden  7/2/2020 22:23   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://twitter.com/JoeBiden/status/1278833330...   \n",
       "1  https://twitter.com/JoeBiden/status/1278809602...   \n",
       "2  https://twitter.com/JoeBiden/status/1278776708...   \n",
       "3  https://twitter.com/JoeBiden/status/1278747263...   \n",
       "4  https://twitter.com/JoeBiden/status/1278733658...   \n",
       "\n",
       "                                               tweet  retweets   likes  \n",
       "0           Wear a mask. pic. twitter.com/HBDMNA4ary     18191   92047  \n",
       "1  Let me be clear: There’s no victory to be cele...     10644   47486  \n",
       "2  This is a job Donald Trump is entirely unfit f...     15149   51443  \n",
       "3  “Mr. President, it's too much.”pic.twitter.com...     44466  137553  \n",
       "4  This is a shameful move. Now is the time for e...      6357   23150  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/stepthom/NLP_course/main/data/JoeBidenTweets.csv\")\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id', 'username', 'link', 'retweets', 'likes'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>tweet_clean_filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7/3/2020 5:00</td>\n",
       "      <td>Wear a mask. pic. twitter.com/HBDMNA4ary</td>\n",
       "      <td>wear mask pic twittercomhbdmna4ary</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/3/2020 3:25</td>\n",
       "      <td>Let me be clear: There’s no victory to be cele...</td>\n",
       "      <td>let clear theres victory celebrated still near...</td>\n",
       "      <td>be no be were is not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/3/2020 1:15</td>\n",
       "      <td>This is a job Donald Trump is entirely unfit f...</td>\n",
       "      <td>job donald trump entirely unfit forpictwitterc...</td>\n",
       "      <td>this is donald trump is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/2/2020 23:18</td>\n",
       "      <td>“Mr. President, it's too much.”pic.twitter.com...</td>\n",
       "      <td>mr president muchpictwittercomweebjipkgj</td>\n",
       "      <td>president its</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7/2/2020 22:23</td>\n",
       "      <td>This is a shameful move. Now is the time for e...</td>\n",
       "      <td>shameful move time employers empathy families ...</td>\n",
       "      <td>this is is time for have for its time for pres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp                                              tweet  \\\n",
       "0   7/3/2020 5:00           Wear a mask. pic. twitter.com/HBDMNA4ary   \n",
       "1   7/3/2020 3:25  Let me be clear: There’s no victory to be cele...   \n",
       "2   7/3/2020 1:15  This is a job Donald Trump is entirely unfit f...   \n",
       "3  7/2/2020 23:18  “Mr. President, it's too much.”pic.twitter.com...   \n",
       "4  7/2/2020 22:23  This is a shameful move. Now is the time for e...   \n",
       "\n",
       "                                         tweet_clean  \\\n",
       "0                 wear mask pic twittercomhbdmna4ary   \n",
       "1  let clear theres victory celebrated still near...   \n",
       "2  job donald trump entirely unfit forpictwitterc...   \n",
       "3           mr president muchpictwittercomweebjipkgj   \n",
       "4  shameful move time employers empathy families ...   \n",
       "\n",
       "                                  tweet_clean_filter  \n",
       "0                                                     \n",
       "1                               be no be were is not  \n",
       "2                            this is donald trump is  \n",
       "3                                      president its  \n",
       "4  this is is time for have for its time for pres...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from bs4 import BeautifulSoup\n",
    "import unidecode\n",
    "\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "stop_words = set(stopwords.words('english') + stopwords.words('spanish'))\n",
    "\n",
    "lemmer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(x):\n",
    "    # Remove HTML tags\n",
    "    # (A note about the warnings: BeautifulSoup is throwing lots of DepecationWarnings, and \n",
    "    # I just don't want to see them right now.)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "        x = BeautifulSoup(x, \"lxml\").get_text()\n",
    "\n",
    "    # Lower case\n",
    "    x = x.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    x = re.sub(r'[^\\w\\s]', '', x)\n",
    "    \n",
    "    # Remove non-unicode\n",
    "    x = unidecode.unidecode(x)\n",
    "    \n",
    "    # Remove numbers\n",
    "    #x = re.sub(r'\\d+', '', x)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    x = ' '.join([w for w in x.split() if w not in stop_words])\n",
    "    \n",
    "    # Lemmatize\n",
    "    #x = ' '.join([lemmer.lemmatize(w) for w in x.split()])\n",
    "    \n",
    "    return x\n",
    "\n",
    "df['tweet_clean'] = df['tweet'].apply(preprocess)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>tweet_clean_filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7/3/2020 5:00</td>\n",
       "      <td>Wear a mask. pic. twitter.com/HBDMNA4ary</td>\n",
       "      <td>wear mask pic twittercomhbdmna4ary</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/3/2020 3:25</td>\n",
       "      <td>Let me be clear: There’s no victory to be cele...</td>\n",
       "      <td>let clear theres victory celebrated still near...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/3/2020 1:15</td>\n",
       "      <td>This is a job Donald Trump is entirely unfit f...</td>\n",
       "      <td>job donald trump entirely unfit forpictwitterc...</td>\n",
       "      <td>donald trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/2/2020 23:18</td>\n",
       "      <td>“Mr. President, it's too much.”pic.twitter.com...</td>\n",
       "      <td>mr president muchpictwittercomweebjipkgj</td>\n",
       "      <td>president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7/2/2020 22:23</td>\n",
       "      <td>This is a shameful move. Now is the time for e...</td>\n",
       "      <td>shameful move time employers empathy families ...</td>\n",
       "      <td>time time president trump get</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp                                              tweet  \\\n",
       "0   7/3/2020 5:00           Wear a mask. pic. twitter.com/HBDMNA4ary   \n",
       "1   7/3/2020 3:25  Let me be clear: There’s no victory to be cele...   \n",
       "2   7/3/2020 1:15  This is a job Donald Trump is entirely unfit f...   \n",
       "3  7/2/2020 23:18  “Mr. President, it's too much.”pic.twitter.com...   \n",
       "4  7/2/2020 22:23  This is a shameful move. Now is the time for e...   \n",
       "\n",
       "                                         tweet_clean  \\\n",
       "0                 wear mask pic twittercomhbdmna4ary   \n",
       "1  let clear theres victory celebrated still near...   \n",
       "2  job donald trump entirely unfit forpictwitterc...   \n",
       "3           mr president muchpictwittercomweebjipkgj   \n",
       "4  shameful move time employers empathy families ...   \n",
       "\n",
       "              tweet_clean_filter  \n",
       "0                                 \n",
       "1                                 \n",
       "2                   donald trump  \n",
       "3                      president  \n",
       "4  time time president trump get  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, \n",
    "                             min_df=0.05, \n",
    "                             max_features=300, \n",
    "                             ngram_range=[1,3])\n",
    "\n",
    "vectorizer = vectorizer.fit(df['tweet_clean'])\n",
    "\n",
    "dtm = vectorizer.transform(df['tweet_clean'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "def filter_words(x):\n",
    "    return ' '.join([w for w in x.split() if w in feature_names])\n",
    "\n",
    "# Create a new column, which is the same as tweet_clean, but only keeps the \n",
    "# words from the vectorizer's vocabulary\n",
    "df['tweet_clean_filter'] = df['tweet_clean'].apply(filter_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TopicID  Support50  Support10      Weight  \\\n",
      "0         0        128        336  214.984897   \n",
      "1         1         61        262  158.569902   \n",
      "2         2        198        549  323.610483   \n",
      "3         3        106        182  170.400497   \n",
      "4         4         58        326  166.835626   \n",
      "5         5         56        339  171.391695   \n",
      "6         6        130        300  193.322127   \n",
      "7         7          1          6   82.882537   \n",
      "8         8         42        200  143.195407   \n",
      "9         9        164        255  185.048114   \n",
      "10       10         53        404  177.550548   \n",
      "11       11          0          0   80.750227   \n",
      "12       12         47        282  155.175387   \n",
      "13       13         91        164  144.851825   \n",
      "14       14         74        361  184.212644   \n",
      "15       15         40        324  166.014882   \n",
      "16       16         81        311  183.385425   \n",
      "17       17         57        278  159.050056   \n",
      "18       18          0          0   80.750227   \n",
      "19       19         10         22   90.575766   \n",
      "20       20         31        222  138.694930   \n",
      "21       21         61        359  173.413231   \n",
      "22       22         70        310  173.163533   \n",
      "23       23         52        322  162.346267   \n",
      "24       24         36         65  112.696507   \n",
      "25       25         53        299  164.981284   \n",
      "26       26         21        111  120.834007   \n",
      "27       27         66        375  177.805150   \n",
      "28       28         54        267  156.756593   \n",
      "29       29          0          0   80.750227   \n",
      "\n",
      "                                                Terms  \n",
      "0   health care president every american need trum...  \n",
      "1   america president nation one trump biden us co...  \n",
      "2   donald donald trump trump nation get president...  \n",
      "3   vp biden president day america get people trum...  \n",
      "4   make president need country trump donald get u...  \n",
      "5   today president country im biden us make day n...  \n",
      "6   biden president vp today make one country amer...  \n",
      "7   one country president im day nation make need ...  \n",
      "8   day one president need country donald trump ge...  \n",
      "9   president country today biden vp make trump da...  \n",
      "10  country president im get people trump today ev...  \n",
      "11  vp us american biden care country day donald d...  \n",
      "12  one president get need nation today america us...  \n",
      "13  vp biden president today us country take get p...  \n",
      "14  im president country today take nation make ge...  \n",
      "15  american president people trump every donald n...  \n",
      "16  trump president need american us people one ge...  \n",
      "17  get president need country trump one people do...  \n",
      "18  vp us american biden care country day donald d...  \n",
      "19  us president nation people trump need today co...  \n",
      "20  every president american need one make country...  \n",
      "21  people president american trump country today ...  \n",
      "22  time president trump country need donald get o...  \n",
      "23  need president trump american get one country ...  \n",
      "24  need president one country day health make tim...  \n",
      "25  take president donald get need one country nat...  \n",
      "26  day every president country american trump mak...  \n",
      "27  us president nation trump donald need country ...  \n",
      "28  nation president us donald today one need trum...  \n",
      "29  vp us american biden care country day donald d...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=30,\n",
    "                                      #doc_topic_prior=alpha,\n",
    "                                      #topic_word_prior=beta,\n",
    "                                      max_iter=200, \n",
    "                                      learning_method='batch', \n",
    "                                      random_state=123,\n",
    "                                      n_jobs=2,\n",
    "                                      verbose=0)\n",
    "lda_output = lda_model.fit(dtm)\n",
    "\n",
    "# Log Likelyhood: Higher the better\n",
    "ll = lda_model.score(dtm)\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "perp = lda_model.perplexity(dtm)\n",
    "\n",
    "# Theta = document-topic matrix\n",
    "# Beta = components_ = topic-term matrix\n",
    "theta = pd.DataFrame(lda_model.transform(dtm))\n",
    "beta = pd.DataFrame(lda_model.components_)\n",
    "\n",
    "# Build Topic Summary\n",
    "no_top_words = 10\n",
    "weight = theta.sum(axis=0)\n",
    "support50 = (theta > 0.5).sum(axis=0)\n",
    "support10 = (theta > 0.1).sum(axis=0)\n",
    "termss = list()\n",
    "for topic_id, topic in enumerate(lda_model.components_):\n",
    "    terms = \" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
    "    termss.append(terms)\n",
    "topic_summary = pd.DataFrame({'TopicID': range(0, len(termss)), \"Support50\": support50, \"Support10\": support10, \"Weight\": weight, \"Terms\": termss})\n",
    "\n",
    "print(topic_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Topics with LDAVis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyLDAvis\\sklearn.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(lda_model, dtm, vectorizer, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m     94\u001b[0m     \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics)\u001b[0m\n\u001b[0;32m    396\u001b[0m    \u001b[0mterm_frequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm_topic_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m    \u001b[0mtopic_info\u001b[0m         \u001b[1;33m=\u001b[0m \u001b[0m_topic_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_term_dists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_proportion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterm_topic_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m    \u001b[0mtoken_table\u001b[0m        \u001b[1;33m=\u001b[0m \u001b[0m_token_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterm_topic_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m    \u001b[0mtopic_coordinates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_topic_coordinates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_term_dists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_proportion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py\u001b[0m in \u001b[0;36m_topic_info\u001b[1;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m    top_terms = pd.concat(Parallel(n_jobs=n_jobs)(delayed(_find_relevance_chunks)(log_ttd, log_lift, R, ls) \\\n\u001b[1;32m--> 255\u001b[1;33m                                                  for ls in _job_chunks(lambda_seq, n_jobs)))\n\u001b[0m\u001b[0;32m    256\u001b[0m    \u001b[0mtopic_dfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_top_term_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_terms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdefault_term_info\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_dfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pyLDAvis.sklearn\n",
    " \n",
    "pyLDAvis.enable_notebook()\n",
    "% time pyLDAvis.sklearn.prepare(lda_model, dtm, vectorizer, mds=\"tsne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
